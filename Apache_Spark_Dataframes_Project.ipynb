{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbX8Ie_SyVkN"
      },
      "source": [
        "# Apache Spark DataFrames Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Importation and Exploration"
      ],
      "metadata": {
        "id": "l7-j3NnxPfkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites"
      ],
      "metadata": {
        "id": "ZTHvtmX2PR_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DEzGDzHyhml",
        "outputId": "c8f4f638-d887-4672-ab52-4ba26c873455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.2)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "# Installing pyspark\n",
        "# ---\n",
        "\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8OgwERbqzHsK"
      },
      "outputs": [],
      "source": [
        "#Then run a local spark session\n",
        "# ---\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw6F-JlZ0POq"
      },
      "source": [
        "### Open the CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTk1Sjzs0Sfi",
        "outputId": "3ad95835-09c5-4b66-f1d7-eed978ab29a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date,Open,High,Low,Close,Volume,Adj Close\n",
            "\n",
            "2012-01-03,59.970001,61.060001,59.869999,60.330002,12668800,52.619234999999996\n",
            "\n",
            "2012-01-04,60.209998999999996,60.349998,59.470001,59.709998999999996,9593300,52.078475\n",
            "\n",
            "2012-01-05,59.349998,59.619999,58.369999,59.419998,12768200,51.825539\n",
            "\n"
          ]
        }
      ],
      "source": [
        "f = open('saf_stock.csv')\n",
        "\n",
        "for i in range(0,4):\n",
        "    print(f.readline())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAFmwm0A1Syp"
      },
      "source": [
        "### Make observations about the schema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89sBoUP41XU0",
        "outputId": "39b84a64-3819-4eb8-8b9a-1624318df70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: timestamp (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SQLContext\n",
        "\n",
        "# Pass in the SparkContext object `sc`\n",
        "sqlCtx = SQLContext(sc)\n",
        "\n",
        "# Read CSV data into a DataFrame object `df`\n",
        "\n",
        "df = sqlCtx.read.csv(\"saf_stock.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Print the type\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determine the column names\n"
      ],
      "metadata": {
        "id": "xzRhSEYBP_7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsfHujQkGAyH",
        "outputId": "c2fb9d65-49fd-4fbb-89f5-c7a8aa591c93"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show first 5 rows"
      ],
      "metadata": {
        "id": "9mE0J9p3EbG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.limit(5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akIDVb_a-xF8",
        "outputId": "e1cb98d4-4ddc-4a3e-a8bc-711a16907286"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|               Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03 00:00:00|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04 00:00:00|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05 00:00:00|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06 00:00:00|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09 00:00:00|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the describe method to learn about the data frame"
      ],
      "metadata": {
        "id": "9swjY1vZEqUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIlHMI8lEr5c",
        "outputId": "4ebc409e-3751-42f9-bf1e-4d27cbe95e1b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "KKnXNCH6N9u_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Format all the data to 2 decimal places i.e. format_number()\n"
      ],
      "metadata": {
        "id": "bAc4vig8OEc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "\n",
        "for column in columns:\n",
        "  df = df.withColumn(column, format_number(column,2))\n",
        "\n",
        "df.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwofEOokONfr",
        "outputId": "e2f7626e-5959-4ea0-c345-af1fce8afcfb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-----+-----+-----+-------------+---------+\n",
            "|               Date| Open| High|  Low|Close|       Volume|Adj Close|\n",
            "+-------------------+-----+-----+-----+-----+-------------+---------+\n",
            "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12,668,800.00|    52.62|\n",
            "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9,593,300.00|    52.08|\n",
            "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12,768,200.00|    51.83|\n",
            "|2012-01-06 00:00:00|59.42|59.45|58.87|59.00| 8,069,400.00|    51.46|\n",
            "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6,679,300.00|    51.62|\n",
            "|2012-01-10 00:00:00|59.43|59.71|58.98|59.04| 6,907,300.00|    51.49|\n",
            "|2012-01-11 00:00:00|59.06|59.53|59.04|59.40| 6,365,600.00|    51.81|\n",
            "|2012-01-12 00:00:00|59.79|60.00|59.40|59.50| 7,236,400.00|    51.90|\n",
            "|2012-01-13 00:00:00|59.18|59.61|59.01|59.54| 7,729,300.00|    51.93|\n",
            "|2012-01-17 00:00:00|59.87|60.11|59.52|59.85| 8,500,000.00|    52.20|\n",
            "+-------------------+-----+-----+-----+-----+-------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a new data frame with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day"
      ],
      "metadata": {
        "id": "27Fy6VYAPPH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = df.withColumn(\"HV Ratio\", df.High/df.Volume).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKpqv0euSjXv",
        "outputId": "8419d298-025d-4fa7-a57e-6ef9c0c8fee2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-----+-----+-----+-------------+---------+--------+\n",
            "|               Date| Open| High|  Low|Close|       Volume|Adj Close|HV Ratio|\n",
            "+-------------------+-----+-----+-----+-----+-------------+---------+--------+\n",
            "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12,668,800.00|    52.62|    null|\n",
            "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9,593,300.00|    52.08|    null|\n",
            "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12,768,200.00|    51.83|    null|\n",
            "|2012-01-06 00:00:00|59.42|59.45|58.87|59.00| 8,069,400.00|    51.46|    null|\n",
            "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6,679,300.00|    51.62|    null|\n",
            "|2012-01-10 00:00:00|59.43|59.71|58.98|59.04| 6,907,300.00|    51.49|    null|\n",
            "|2012-01-11 00:00:00|59.06|59.53|59.04|59.40| 6,365,600.00|    51.81|    null|\n",
            "|2012-01-12 00:00:00|59.79|60.00|59.40|59.50| 7,236,400.00|    51.90|    null|\n",
            "|2012-01-13 00:00:00|59.18|59.61|59.01|59.54| 7,729,300.00|    51.93|    null|\n",
            "|2012-01-17 00:00:00|59.87|60.11|59.52|59.85| 8,500,000.00|    52.20|    null|\n",
            "|2012-01-18 00:00:00|59.79|60.03|59.65|60.01| 5,911,400.00|    52.34|    null|\n",
            "|2012-01-19 00:00:00|59.93|60.73|59.75|60.61| 9,234,600.00|    52.86|    null|\n",
            "|2012-01-20 00:00:00|60.75|61.25|60.67|61.01|10,378,800.00|    53.21|    null|\n",
            "|2012-01-23 00:00:00|60.81|60.98|60.51|60.91| 7,134,100.00|    53.13|    null|\n",
            "|2012-01-24 00:00:00|60.75|62.00|60.75|61.39| 7,362,800.00|    53.54|    null|\n",
            "|2012-01-25 00:00:00|61.18|61.61|61.04|61.47| 5,915,800.00|    53.61|    null|\n",
            "|2012-01-26 00:00:00|61.80|61.84|60.77|60.97| 7,436,200.00|    53.18|    null|\n",
            "|2012-01-27 00:00:00|60.86|61.12|60.54|60.71| 6,287,300.00|    52.95|    null|\n",
            "|2012-01-30 00:00:00|60.47|61.32|60.35|61.30| 7,636,900.00|    53.47|    null|\n",
            "|2012-01-31 00:00:00|61.53|61.57|60.58|61.36| 9,761,500.00|    53.52|    null|\n",
            "+-------------------+-----+-----+-----+-----+-------------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis\n"
      ],
      "metadata": {
        "id": "vt_LfPcyZ13j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What day had the Peak High in Price?"
      ],
      "metadata": {
        "id": "2j4rEQMSZ7qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "peak_high_price = df.orderBy(desc(\"High\")).select(\"Date\").first()[0] \n",
        "bold = '\\033[1m' \n",
        "print(bold + \"The day with the highest peak price is:\", peak_high_price)\n",
        "    "
      ],
      "metadata": {
        "id": "o1611pO9aBha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecf956d-388d-425b-f6db-18716af7e619"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe day with the highest peak price is: 2015-01-13 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  What is the mean of the Close column?\n"
      ],
      "metadata": {
        "id": "2RVU7L3vUZNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import format_number, year, month, dayofmonth, max, mean, corr, min \n",
        "\n",
        "close_mean = df.select(mean(\"Close\")).first()[0] \n",
        "print(bold +\"The mean of the close column is:\", close_mean)      \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCghU88VUZ4e",
        "outputId": "babb5f9c-47af-4b38-d29f-033ab66c5833"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe mean of the close column is: 72.38844992050863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is the max and min of the Volume column?"
      ],
      "metadata": {
        "id": "QrdC6f5iU9Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import format_number, year, month, dayofmonth, max, mean, corr, min \n",
        "\n",
        "max_vol = df.select(max(\"Volume\")).first()[0] \n",
        "min_vol = df.select(min(\"Volume\")).first()[0] \n",
        "print(bold +\"The maximum volume is:\", max_vol) \n",
        "print(\"The minimum volume is:\", min_vol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzwKVBJ6VBr3",
        "outputId": "62246673-93fa-41b5-dada-037d7dd7768b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe maximum volume is: 9,994,400.00\n",
            "The minimum volume is: 10,010,500.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  How many days was the Close lower than 60 dollars?"
      ],
      "metadata": {
        "id": "R8IfPOftV-Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "days_less_60 = df.filter(\"Close < 60\").count() \n",
        "print(bold +\"The number of days when the Close was lower than 60 dollars is:\", days_less_60, \"days\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3QTbpJKWDFW",
        "outputId": "a5c42d0a-03ad-4397-8534-2e107843d587"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe number of days when the Close was lower than 60 dollars is: 81 days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  What percentage of the time was the High greater than 80 dollars?"
      ],
      "metadata": {
        "id": "GlLx8LV2Wez2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count \n",
        " \n",
        "high_more_than_80 = df.filter(\"High > 80\") \n",
        "percent = (high_more_than_80.count() / df.count()) * 100 \n",
        "print(bold + \"The percentage of the time when the High was greater than 80 dollars is: {:.2f}%\".format(percent))      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8a74J4LWjDE",
        "outputId": "69f1bcd0-d8cc-4a51-f8c3-0645b839ee09"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe percentage of the time when the High was greater than 80 dollars is: 8.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  What is the max High per year?\n"
      ],
      "metadata": {
        "id": "UcRkGNg6X7gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import format_number, year, month, dayofmonth, max, mean, corr, min \n",
        "\n",
        "max_high_year = df.groupBy(year(\"Date\")).agg(max(\"High\")) \n",
        "max_high_year.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoDjgazuYBIm",
        "outputId": "97ced561-ff53-4d16-e933-b1d3ba885e29"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|year(Date)|max(High)|\n",
            "+----------+---------+\n",
            "|      2012|    77.60|\n",
            "|      2013|    81.37|\n",
            "|      2014|    88.09|\n",
            "|      2015|    90.97|\n",
            "|      2016|    75.19|\n",
            "+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  What is the average Close for each Calendar Month?"
      ],
      "metadata": {
        "id": "xC35H_udYXf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import format_number, year, month, dayofmonth, max, mean, corr, min, avg, desc \n",
        "\n",
        "avg_close_per_month = df.groupBy(month(\"Date\")).agg(avg(\"Close\")) \n",
        "avg_close_per_month.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBJ3_KNvYbz7",
        "outputId": "394d8c0e-3adf-47be-90ea-74556f0a847d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+\n",
            "|month(Date)|       avg(Close)|\n",
            "+-----------+-----------------+\n",
            "|         12|72.84792452830189|\n",
            "|          1|71.44801980198022|\n",
            "|          6|72.49537735849057|\n",
            "|          3|71.77794392523363|\n",
            "|          5|72.30971698113206|\n",
            "|          9|72.18411764705883|\n",
            "|          4|72.97361904761907|\n",
            "|          8|73.02981818181819|\n",
            "|          7|74.43971962616824|\n",
            "|         10|71.57854545454546|\n",
            "|         11|72.11108910891085|\n",
            "|          2|71.30680412371134|\n",
            "+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}